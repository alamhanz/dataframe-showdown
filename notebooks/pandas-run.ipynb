{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import shutil\n",
    "import gc\n",
    "import joblib\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_DATA = '../../df-showdown-data/'\n",
    "PATH_DATA = 'O:/df-showdown-data/'\n",
    "TEMP_PATH = PATH_DATA+'temp/'\n",
    "PATH_OUTPUT = '../output/'\n",
    "\n",
    "SLA_NAME = 'pandas-sla.pkl'\n",
    "MEM_NAME = 'pandas-mem.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sla = {}\n",
    "all_memory = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory():\n",
    "    est_memory = psutil.virtual_memory()[3]/1000000000\n",
    "    return est_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sla = joblib.load(PATH_OUTPUT+SLA_NAME)\n",
    "all_memory = joblib.load(PATH_OUTPUT+MEM_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##     Task1 & Task2- I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sla['task1'] = {}\n",
    "all_sla['task1']['csv'] = {}\n",
    "all_sla['task1']['prq'] = {}\n",
    "\n",
    "all_sla['task2'] = {}\n",
    "all_sla['task2']['csv'] = {}\n",
    "all_sla['task2']['prq'] = {}\n",
    "\n",
    "\n",
    "\n",
    "all_memory['task1'] = {}\n",
    "all_memory['task1']['csv'] = {}\n",
    "all_memory['task1']['prq'] = {}\n",
    "\n",
    "all_memory['task2'] = {}\n",
    "all_memory['task2']['csv'] = {}\n",
    "all_memory['task2']['prq'] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 2147483648 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     39\u001b[0m start_mem \u001b[39m=\u001b[39m get_memory()\n\u001b[1;32m---> 40\u001b[0m dtemp1\u001b[39m.\u001b[39;49mto_parquet(TEMP_PATH \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtemp.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m,index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     41\u001b[0m end_mem \u001b[39m=\u001b[39m get_memory() \u001b[39m-\u001b[39m start_mem\n\u001b[0;32m     42\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\core\\frame.py:2888\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2801\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2884\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   2885\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2886\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 2888\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   2889\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2890\u001b[0m     path,\n\u001b[0;32m   2891\u001b[0m     engine,\n\u001b[0;32m   2892\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   2893\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2894\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[0;32m   2895\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2896\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2897\u001b[0m )\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\io\\parquet.py:411\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m    409\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[1;32m--> 411\u001b[0m impl\u001b[39m.\u001b[39;49mwrite(\n\u001b[0;32m    412\u001b[0m     df,\n\u001b[0;32m    413\u001b[0m     path_or_buf,\n\u001b[0;32m    414\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    415\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m    416\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[0;32m    417\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    418\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    419\u001b[0m )\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, io\u001b[39m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\io\\parquet.py:159\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     from_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpreserve_index\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m index\n\u001b[1;32m--> 159\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pandas(df, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfrom_pandas_kwargs)\n\u001b[0;32m    161\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    162\u001b[0m     path,\n\u001b[0;32m    163\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m     is_dir\u001b[39m=\u001b[39mpartition_cols \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    167\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    169\u001b[0m     \u001b[39misinstance\u001b[39m(path_or_handle, io\u001b[39m.\u001b[39mBufferedWriter)\n\u001b[0;32m    170\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(path_or_handle, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_handle\u001b[39m.\u001b[39mname, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m))\n\u001b[0;32m    172\u001b[0m ):\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pyarrow\\table.pxi:3475\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pyarrow\\pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[39mfor\u001b[39;00m i, maybe_fut \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arrays):\n\u001b[0;32m    623\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_fut, futures\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m--> 624\u001b[0m             arrays[i] \u001b[39m=\u001b[39m maybe_fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    626\u001b[0m types \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mtype \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m    628\u001b[0m \u001b[39mif\u001b[39;00m schema \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\droid2-1\\lib\\concurrent\\futures\\_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\droid2-1\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\droid2-1\\lib\\concurrent\\futures\\thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pyarrow\\pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    589\u001b[0m     type_ \u001b[39m=\u001b[39m field\u001b[39m.\u001b[39mtype\n\u001b[0;32m    591\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(col, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49mtype_, from_pandas\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, safe\u001b[39m=\u001b[39;49msafe)\n\u001b[0;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pyarrow\\array.pxi:316\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pyarrow\\array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pyarrow\\error.pxi:117\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: realloc of size 2147483648 failed"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    if i<=5:\n",
    "        fn = 'data_{}.csv'.format(i)\n",
    "        start = time.perf_counter()\n",
    "        start_mem = get_memory()\n",
    "        dtemp1 = pd.read_csv(PATH_DATA+fn, memory_map=True)\n",
    "        end_mem = get_memory() - start_mem\n",
    "        end = time.perf_counter() - start\n",
    "        nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "        all_sla['task1']['csv'][nrows]=end\n",
    "        all_memory['task1']['csv'][nrows]=end_mem\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        start_mem = get_memory()\n",
    "        dtemp1.to_csv(TEMP_PATH + 'temp.csv',index=False)\n",
    "        end_mem = get_memory() - start_mem\n",
    "        end = time.perf_counter() - start\n",
    "        all_sla['task2']['csv'][nrows]=end\n",
    "        all_memory['task2']['csv'][nrows]=end_mem\n",
    "\n",
    "        del dtemp1\n",
    "        time.sleep(3)\n",
    "        gc.collect()\n",
    "        os.remove(TEMP_PATH + 'temp.csv')\n",
    "        time.sleep(2)\n",
    "\n",
    "    fn = 'data_{}.parquet'.format(i)\n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    dtemp1 = pd.read_parquet(PATH_DATA+fn)\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "    all_sla['task1']['prq'][nrows]=end\n",
    "    all_memory['task1']['prq'][nrows]=end_mem\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    dtemp1.to_parquet(TEMP_PATH + 'temp.parquet',index=False)\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    all_sla['task2']['prq'][nrows]=end\n",
    "    all_memory['task2']['prq'][nrows]=end_mem\n",
    "\n",
    "    del dtemp1\n",
    "    time.sleep(3)\n",
    "    gc.collect()\n",
    "    os.remove(TEMP_PATH + 'temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task1': {'csv': {'0': 0.21707010000000082,\n",
       "   '1': 1.3089221999999978,\n",
       "   '5': 5.806964999999998,\n",
       "   '10': 11.499586900000011,\n",
       "   '25': 28.97800269999999,\n",
       "   '50': 57.918214999999975},\n",
       "  'prq': {'0': 0.21078939999999946,\n",
       "   '1': 0.4163245999999958,\n",
       "   '5': 1.6410219000000126,\n",
       "   '10': 3.2663220000000024,\n",
       "   '25': 8.317832299999964,\n",
       "   '50': 16.951192300000002,\n",
       "   '75': 23.721178800000075,\n",
       "   '100': 32.56295439999997,\n",
       "   '130': 42.39577080000004,\n",
       "   '175': 74.35042620000002}},\n",
       " 'task2': {'csv': {'0': 0.5463624999999972,\n",
       "   '1': 3.7516605,\n",
       "   '5': 18.163135999999994,\n",
       "   '10': 36.30226119999999,\n",
       "   '25': 91.17573209999998,\n",
       "   '50': 183.80385190000004},\n",
       "  'prq': {'0': 0.10909129999999934,\n",
       "   '1': 0.6284197999999961,\n",
       "   '5': 2.8248853999999994,\n",
       "   '10': 5.8992885000000115,\n",
       "   '25': 14.567097499999988,\n",
       "   '50': 29.08308450000004,\n",
       "   '75': 44.02544180000007,\n",
       "   '100': 58.604622500000005,\n",
       "   '130': 87.35506480000004}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task1': {'csv': {'0': 0.024510463999999565,\n",
       "   '1': 0.13008896000000014,\n",
       "   '5': 0.5812510719999997,\n",
       "   '10': 1.1686789120000007,\n",
       "   '25': 2.8759039999999993,\n",
       "   '50': 5.799350271999999},\n",
       "  'prq': {'0': 0.08231321600000019,\n",
       "   '1': 0.14975385600000024,\n",
       "   '5': 0.4823900159999992,\n",
       "   '10': 0.7670333440000006,\n",
       "   '25': 1.8859991040000006,\n",
       "   '50': 4.049760256,\n",
       "   '75': 4.794556416000001,\n",
       "   '100': 5.632434176,\n",
       "   '130': 7.968747519999999,\n",
       "   '175': 15.595823104}},\n",
       " 'task2': {'csv': {'0': -0.01115340799999931,\n",
       "   '1': 0.004321280000000094,\n",
       "   '5': 0.0043171840000004735,\n",
       "   '10': 0.06634700800000015,\n",
       "   '25': 0.04214783999999838,\n",
       "   '50': -0.45188710400000076},\n",
       "  'prq': {'0': 0.019476479999999796,\n",
       "   '1': 0.1183621119999998,\n",
       "   '5': 0.13698252800000077,\n",
       "   '10': 0.09502719999999965,\n",
       "   '25': 0.09743564799999938,\n",
       "   '50': 0.13913292800000043,\n",
       "   '75': 0.0030392319999990036,\n",
       "   '100': -0.4301250560000014,\n",
       "   '130': -9.483775999999999}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del dtemp1\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data for other task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = [pd.read_parquet(PATH_DATA+'data_{}.parquet'.format(i)) for i in [4,5,6,7]]\n",
    "df_right = pd.read_parquet(PATH_DATA+'data_to_join.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3 - Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_task = 'task3'\n",
    "all_sla[n_task] = {}\n",
    "all_memory[n_task] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.02\n",
      "50.04\n",
      "75.06\n",
      "100.08\n"
     ]
    }
   ],
   "source": [
    "for dtemp1 in all_df:\n",
    "    print(round(len(dtemp1)/1000000,2))\n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    dtemp2 = dtemp1.sort_values(['Date','Amount'],ascending=[True,False])\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "    \n",
    "    all_sla[n_task][nrows]=end\n",
    "    all_memory[n_task][nrows]=end_mem\n",
    "\n",
    "    del dtemp1\n",
    "    del dtemp2\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 5.538272900000038,\n",
       " '50': 24.783460200000036,\n",
       " '75': 33.553642699999955,\n",
       " '100': 43.79307779999999}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sla[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 1.2487393279999992,\n",
       " '50': 0.7335321599999993,\n",
       " '75': 5.145772032,\n",
       " '100': 2.145640447999998}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_memory[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task4 - Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_task = 'task4'\n",
    "all_sla[n_task] = {}\n",
    "all_memory[n_task] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.02\n",
      "50.04\n",
      "75.06\n",
      "100.08\n"
     ]
    }
   ],
   "source": [
    "# dtemp1 = all_df[0]\n",
    "filt1 = ['Shipped - Delivered to Buyer', 'Cancelled']\n",
    "for dtemp1 in all_df:\n",
    "    print(round(len(dtemp1)/1000000,2))\n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    dtemp2 = dtemp1[(dtemp1['Amount']>300) & (~dtemp1['Status'].isin(filt1))]\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "    \n",
    "    all_sla[n_task][nrows]=end\n",
    "    all_memory[n_task][nrows]=end_mem\n",
    "\n",
    "    del dtemp1\n",
    "    del dtemp2\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 2.1126372999999603,\n",
       " '50': 4.223625699999957,\n",
       " '75': 5.0990271000000575,\n",
       " '100': 6.902770900000178}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sla[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 1.6212295680000004,\n",
       " '50': 1.7223065599999998,\n",
       " '75': 2.263240704000001,\n",
       " '100': 2.9106831359999994}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_memory[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task5 - Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_task = 'task5'\n",
    "all_sla[n_task] = {}\n",
    "all_memory[n_task] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.02\n",
      "50.04\n",
      "75.06\n",
      "100.08\n"
     ]
    }
   ],
   "source": [
    "for dtemp1 in all_df:\n",
    "    print(round(len(dtemp1)/1000000,2))\n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    dtemp2 = pd.merge(dtemp1,df_right,on=['Date','ship-service-level'],how='left')\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "\n",
    "    all_sla[n_task][nrows]=end\n",
    "    all_memory[n_task][nrows]=end_mem\n",
    "\n",
    "    del dtemp1\n",
    "    del dtemp2\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n",
    "    time.sleep(4)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 3.9637032999999064,\n",
       " '50': 7.664806799999951,\n",
       " '75': 12.460293099999944,\n",
       " '100': 19.737634200000002}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sla[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 1.225998336,\n",
       " '50': 2.3351336959999998,\n",
       " '75': 3.5374899200000023,\n",
       " '100': 3.2817152000000007}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_memory[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task6 - udf apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_task = 'task6'\n",
    "all_sla[n_task] = {}\n",
    "all_memory[n_task] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    x0 = x + 1\n",
    "    for i in range(25):\n",
    "        if x0<800:\n",
    "            x0 += i\n",
    "            x0 = (x0/3.0)*2.5\n",
    "            x0 = x0*1.2\n",
    "        else:\n",
    "            x0 += i/2.0\n",
    "            x0 = (x0/4.0)*3.8\n",
    "\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.02\n",
      "50.04\n",
      "75.06\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 573. MiB for an array with shape (75063450,) and data type uint64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m      6\u001b[0m start_mem \u001b[39m=\u001b[39m get_memory()\n\u001b[1;32m----> 7\u001b[0m dtemp1[\u001b[39m'\u001b[39m\u001b[39mAmount2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dtemp1[\u001b[39m'\u001b[39;49m\u001b[39mAmount\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(fun)\n\u001b[0;32m      8\u001b[0m end_mem \u001b[39m=\u001b[39m get_memory() \u001b[39m-\u001b[39m start_mem\n\u001b[0;32m      9\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2843\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\projects\\all_envs\\dfs\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2443\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 573. MiB for an array with shape (75063450,) and data type uint64"
     ]
    }
   ],
   "source": [
    "# dtemp1=all_df[0]\n",
    "# dtemp1['Amount2'] = dtemp1['Amount'].apply(fun)\n",
    "for dtemp1 in all_df:\n",
    "    print(round(len(dtemp1)/1000000,2))\n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    dtemp1['Amount2'] = dtemp1['Amount'].apply(fun)\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "    \n",
    "    all_sla[n_task][nrows]=end\n",
    "    all_memory[n_task][nrows]=end_mem\n",
    "    \n",
    "    del dtemp1\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n",
    "    time.sleep(4)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 112.1799453000001, '50': 225.9367654}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sla[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 0.5384683519999989, '50': -2.4369602560000008}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_memory[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task7 - aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_task = 'task7'\n",
    "all_sla[n_task] = {}\n",
    "all_memory[n_task] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p25(x):\n",
    "    return np.percentile(x,25)\n",
    "\n",
    "def p75(x):\n",
    "    return np.percentile(x,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.02\n",
      "50.04\n",
      "75.06\n",
      "100.08\n"
     ]
    }
   ],
   "source": [
    "# dtemp1=all_df[0]\n",
    "for dtemp1 in all_df:\n",
    "    print(round(len(dtemp1)/1000000,2))\n",
    "    start = time.perf_counter()\n",
    "    start_mem = get_memory()\n",
    "    # dtemp2 = dtemp1.groupby(['Date','Status']).agg({'Amount':[np.mean, np.size, p25, p75]})\n",
    "    dtemp2 = dtemp1.groupby(['Date','Status']).agg({'Amount':'mean'})\n",
    "\n",
    "    end_mem = get_memory() - start_mem\n",
    "    end = time.perf_counter() - start\n",
    "    nrows = str(int(dtemp1.shape[0]/1000000))\n",
    "    \n",
    "    all_sla[n_task][nrows]=end\n",
    "    all_memory[n_task][nrows]=end_mem\n",
    "\n",
    "    del dtemp1\n",
    "    del dtemp2\n",
    "    time.sleep(4)\n",
    "    gc.collect()\n",
    "    time.sleep(4)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 3.367476599999975,\n",
       " '50': 7.263250599999992,\n",
       " '75': 9.238950799999998,\n",
       " '100': 14.18757690000001}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sla[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25': 0.15176499200000038,\n",
       " '50': -0.06929203199999989,\n",
       " '75': 0.05231001599999985,\n",
       " '100': -0.5718097919999998}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_memory[n_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/pandas-mem.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(all_sla,PATH_OUTPUT+SLA_NAME)\n",
    "joblib.dump(all_memory,PATH_OUTPUT+MEM_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfs",
   "language": "python",
   "name": "dfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
